{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark import Broadcast\n",
    "from pyspark.sql import SparkSession, DataFrame\n",
    "from pyspark.sql.types import StringType, ArrayType, FloatType\n",
    "from itertools import combinations\n",
    "from typing import Iterable, Any, List\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spark initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName('exercise1') \\\n",
    "    .config('spark.master', 'local[*]') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks_df = (spark.read\n",
    "    .option(\"multiline\", \"true\")\n",
    "    .option(\"quote\", '\"')\n",
    "    .option(\"escape\", '\"')\n",
    "    .csv('data/tracks.csv')\n",
    ")\n",
    "\n",
    "# rename columns with row values from first row to second row\n",
    "column_categories = zip(*tracks_df.take(2))\n",
    "columns = tracks_df.columns\n",
    "tracks_df = tracks_df.select(columns[0].alias('track_id'),\n",
    "    *(column.cast(FloatType()).alias(\"-\".join(map(str, categories)))\n",
    "    for column, categories in zip(columns[1:], column_categories[1:]))\n",
    ")\n",
    "\n",
    "tracks_df = (tracks_df\n",
    "    .filter(F.col(\"track_id\").isNotNull()) \n",
    "    .filter(F.col(\"track_id\") != \"track_id\")\n",
    ")\n",
    "\n",
    "tracks_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df = (spark.read\n",
    "    .csv('data/features.csv')\n",
    ")\n",
    "\n",
    "# rename columns with row values from first row to second row\n",
    "column_categories = zip(*features_df.take(3))\n",
    "columns = features_df.columns\n",
    "features_df = features_df.select(columns[0].alias('track_id'),\n",
    "    *(column.cast(FloatType()).alias(\"-\".join(map(str, categories)))\n",
    "    for column, categories in zip(columns[1:], column_categories[1:]))\n",
    ")\n",
    "\n",
    "features_df = (features_df\n",
    "    .filter(F.col(\"track_id\") != \"feature\")\n",
    "    .filter(F.col(\"track_id\") != \"statistics\")\n",
    "    .filter(F.col(\"track_id\") != \"number\")\n",
    "    .filter(F.col(\"track_id\") != \"track_id\")\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agglomerative clustering (in-memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_tracks_df = tracks_df.filter(F.col(\"set-subset\") == \"small\")\n",
    "small_features_df = (features_df\n",
    "    .join(small_tracks_df, \"track_id\", \"left\")\n",
    "    .filter(F.col(\"set-subset\").isNotNull())\n",
    "    .select(features_df.columns)\n",
    ")\n",
    "\n",
    "music_features_pd = (small_features_df\n",
    "    .drop(\"track_id\")\n",
    "    .toPandas()\n",
    ")\n",
    "music_features_pd = music_features_pd.astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the metrics (radius, diameter, density_r, density_d) for each cluster\n",
    "def calculate_metrics(pd_df,centroids):\n",
    "    \n",
    "    cluster = pd_df[\"cluster\"].values[0]\n",
    "    \n",
    "    metrics = pd.DataFrame({'radius': [0], 'diameter': [0],'density_r': [0],'density_d': [0]},columns=['radius', 'diameter','density_r','density_d'])\n",
    "\n",
    "    centroid = centroids[cluster]\n",
    "\n",
    "    for index, row in pd_df.iterrows():\n",
    "\n",
    "        #row to array \n",
    "        a = row.to_numpy()\n",
    "\n",
    "        radius = math.dist(a,centroid)\n",
    "\n",
    "        if radius > metrics.loc[0,'radius']:\n",
    "            metrics.loc[0,'radius'] = radius\n",
    "\n",
    "    # calculater density with radius\n",
    "    metrics.loc[0,'density_r'] = pd_df.size / metrics.loc[0,'radius']**2\n",
    "\n",
    "    all_combinations = list(combinations(range(0,pd_df.size), 2))\n",
    "\n",
    "    for combination in all_combinations:\n",
    "\n",
    "        a = pd_df.iloc[combination[0]].to_numpy()\n",
    "        b = pd_df.iloc[combination[1]].to_numpy()\n",
    "\n",
    "        diameter = math.dist(a,b)\n",
    "\n",
    "        if diameter > metrics.loc[0,'diameter']:\n",
    "            metrics.loc[0,'diameter'] = diameter\n",
    "        \n",
    "    # calculater density with diameter\n",
    "    metrics.loc[0,'density_d'] = pd_df.size / metrics.loc[0,'diameter']**2\n",
    "\n",
    "    return metrics\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "\n",
    "metrics_pd_array = []\n",
    "\n",
    "# i = 8 until 16\n",
    "for i in range(8, 17):\n",
    "    n_clusters = i\n",
    "    clusterer = AgglomerativeClustering(n_clusters=n_clusters, compute_distances=True)\n",
    "    clusterer.fit(music_features_pd)\n",
    "    print(f\"n_clusters: {n_clusters}, cluster_labels: {clusterer.labels_}\")\n",
    "\n",
    "    # calculate centroids\n",
    "\n",
    "    centroid_calculator = NearestCentroid()\n",
    "\n",
    "    centroid_calculator.fit(music_features_pd, clusterer.labels_)\n",
    "\n",
    "    column_categories = music_features_pd\n",
    "    column_categories[\"cluster\"] = clusterer.labels_\n",
    "    \n",
    "    metrics_pd_array.append(column_categories.groupby(\"cluster\").apply(calculate_metrics,centroid_calculator.centroids_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
